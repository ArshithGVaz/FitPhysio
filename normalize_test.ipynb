{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_keypoints(keypoints, anchor_idx1, anchor_idx2):\n",
    "    # Extract reference keypoints\n",
    "    x1, y1 = keypoints[anchor_idx1]\n",
    "    x2, y2 = keypoints[anchor_idx2]\n",
    "\n",
    "    # Calculate the scaling factor (distance between anchor keypoints)\n",
    "    scale = np.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n",
    "\n",
    "    # Calculate the anchor point (e.g., midpoint)\n",
    "    anchor_x, anchor_y = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "\n",
    "    # Normalize all keypoints\n",
    "    normalized_keypoints = []\n",
    "    for x, y in keypoints:\n",
    "        norm_x = (x - anchor_x) / scale\n",
    "        norm_y = (y - anchor_y) / scale\n",
    "        normalized_keypoints.append((norm_x, norm_y))\n",
    "\n",
    "    return np.array(normalized_keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pose_similarity(pose1, pose2):\n",
    "    # Ensure the two poses have the same number of keypoints\n",
    "    assert len(pose1) == len(pose2), \"Poses must have the same number of keypoints\"\n",
    "\n",
    "    # Compute average Euclidean distance\n",
    "    distances = np.sqrt(np.sum((pose1 - pose2) ** 2, axis=1))\n",
    "    return np.mean(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pretrained YOLO11n-pose Pose model\n",
    "model = YOLO(\"yolo11m-pose.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\Users\\uprao\\OneDrive\\Desktop\\MotionMatch\\model\\tframe1.png: 96x160 1 person, 289.3ms\n",
      "Speed: 8.9ms preprocess, 289.3ms inference, 22.3ms postprocess per image at shape (1, 3, 96, 160)\n",
      "Calib image\n",
      "[[[     950.82      368.16]\n",
      "  [     962.82      354.31]\n",
      "  [     936.17      353.59]\n",
      "  [     974.55      365.96]\n",
      "  [     910.03      362.95]\n",
      "  [     997.05      459.97]\n",
      "  [     866.19      455.27]\n",
      "  [     1017.2      570.62]\n",
      "  [     836.81      563.96]\n",
      "  [     1022.8      675.67]\n",
      "  [     836.25      663.35]\n",
      "  [     967.71      676.95]\n",
      "  [     881.57      675.57]\n",
      "  [     957.33      851.62]\n",
      "  [     880.85       853.3]\n",
      "  [     945.87      1002.2]\n",
      "  [     882.83      1005.7]]]\n"
     ]
    }
   ],
   "source": [
    "# Run inference on an image\n",
    "results = model(\"tframe1.png\", conf=0.3, imgsz=160, max_det=1)  # results list\n",
    "for r in results:\n",
    "    pose1 = r.keypoints.xy.numpy()\n",
    "    print(\"Calib image\")\n",
    "    print(pose1)  # print the Keypoints object containing the detected keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\Users\\uprao\\OneDrive\\Desktop\\MotionMatch\\model\\uframe1.png: 96x160 1 person, 121.0ms\n",
      "Speed: 4.4ms preprocess, 121.0ms inference, 1.1ms postprocess per image at shape (1, 3, 96, 160)\n",
      "Test image\n",
      "[[[     997.15      360.81]\n",
      "  [     1011.8      346.19]\n",
      "  [     981.86      345.78]\n",
      "  [     1026.8      358.12]\n",
      "  [     958.14      357.21]\n",
      "  [     1052.9      451.29]\n",
      "  [     923.83      456.15]\n",
      "  [     1077.1      562.16]\n",
      "  [     894.67      576.18]\n",
      "  [     1090.9      661.85]\n",
      "  [     872.84       684.1]\n",
      "  [       1028      664.26]\n",
      "  [      944.3      666.72]\n",
      "  [     1032.6       815.5]\n",
      "  [     957.08      819.03]\n",
      "  [     1022.5      948.06]\n",
      "  [      963.1      953.92]]]\n"
     ]
    }
   ],
   "source": [
    "results2 = model(\"uframe1.png\", conf=0.3, imgsz=160, max_det=1)  # results list\n",
    "for r in results2:\n",
    "    pose2 = r.keypoints.xy.numpy()\n",
    "    print(\"Test image\")\n",
    "    print(pose2)  # print the Keypoints object containing the detected keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "# pose1 = np.array([[100, 200], [120, 220], [110, 250]])  # Keypoints for video 1\n",
    "# pose2 = np.array([[200, 400], [240, 440], [220, 500]])  # Keypoints for video 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0.14663    -0.68319]\n",
      " [    0.23829    -0.78902]\n",
      " [    0.03475     -0.7945]\n",
      " [    0.32791    -0.69998]\n",
      " [   -0.16488    -0.72303]\n",
      " [    0.49968    0.017956]\n",
      " [   -0.49968   -0.017956]\n",
      " [    0.65369     0.86295]\n",
      " [   -0.72406      0.8121]\n",
      " [    0.69632      1.6652]\n",
      " [   -0.72832      1.5712]\n",
      " [    0.27567       1.675]\n",
      " [   -0.38217      1.6644]\n",
      " [    0.19633      3.0089]\n",
      " [   -0.38772      3.0218]\n",
      " [    0.10883      4.1587]\n",
      " [   -0.37261      4.1853]]\n"
     ]
    }
   ],
   "source": [
    "# Normalize poses\n",
    "pose1_normalized = normalize_keypoints(pose1[0], anchor_idx1=5, anchor_idx2=6)\n",
    "print(pose1_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0.068233    -0.71957]\n",
      " [    0.18147    -0.83275]\n",
      " [  -0.050169    -0.83597]\n",
      " [    0.29803    -0.74037]\n",
      " [    -0.2339    -0.74743]\n",
      " [    0.49965   -0.018805]\n",
      " [   -0.49965    0.018805]\n",
      " [    0.68753     0.83979]\n",
      " [   -0.72548     0.94834]\n",
      " [    0.79389      1.6118]\n",
      " [   -0.89452      1.7842]\n",
      " [    0.30746      1.6305]\n",
      " [   -0.34111      1.6496]\n",
      " [      0.343      2.8017]\n",
      " [   -0.24214      2.8291]\n",
      " [    0.26457      3.8284]\n",
      " [   -0.19546      3.8738]]\n"
     ]
    }
   ],
   "source": [
    "pose2_normalized = normalize_keypoints(pose2[0], anchor_idx1=5, anchor_idx2=6)\n",
    "print(pose2_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pose Difference: 14.245955688134938\n"
     ]
    }
   ],
   "source": [
    "# Compute similarity\n",
    "similarity = compute_pose_similarity(pose1_normalized, pose2_normalized)\n",
    "print(\"Pose Difference:\", similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cosine_similarity(pose1, pose2):\n",
    "    # Flatten the keypoints into a single vector\n",
    "    pose1_vector = pose1.flatten()\n",
    "    pose2_vector = pose2.flatten()\n",
    "\n",
    "    # Compute dot product and magnitudes\n",
    "    dot_product = np.dot(pose1_vector, pose2_vector)\n",
    "    magnitude1 = np.linalg.norm(pose1_vector)\n",
    "    magnitude2 = np.linalg.norm(pose2_vector)\n",
    "\n",
    "    # Avoid division by zero\n",
    "    if magnitude1 == 0 or magnitude2 == 0:\n",
    "        return 0  # Treat zero-magnitude vectors as orthogonal\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    return dot_product / (magnitude1 * magnitude2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 1.0\n"
     ]
    }
   ],
   "source": [
    "cos_similarity = compute_cosine_similarity(pose1_normalized, pose2_normalized)\n",
    "print(\"Cosine Similarity:\", cos_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0.69632      1.6652]\n",
      " [   -0.72832      1.5712]]\n"
     ]
    }
   ],
   "source": [
    "print(pose1_normalized[9:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
