{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_keypoints(keypoints, anchor_idx1, anchor_idx2):\n",
    "    # Extract reference keypoints\n",
    "    x1, y1 = keypoints[anchor_idx1]\n",
    "    x2, y2 = keypoints[anchor_idx2]\n",
    "\n",
    "    # Calculate the scaling factor (distance between anchor keypoints)\n",
    "    scale = np.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n",
    "\n",
    "    # Calculate the anchor point (e.g., midpoint)\n",
    "    anchor_x, anchor_y = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "\n",
    "    # Normalize all keypoints\n",
    "    normalized_keypoints = []\n",
    "    for x, y in keypoints:\n",
    "        norm_x = (x - anchor_x) / scale\n",
    "        norm_y = (y - anchor_y) / scale\n",
    "        normalized_keypoints.append((norm_x, norm_y))\n",
    "\n",
    "    return np.array(normalized_keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pose_similarity(pose1, pose2):\n",
    "    # Ensure the two poses have the same number of keypoints\n",
    "    assert len(pose1) == len(pose2), \"Poses must have the same number of keypoints\"\n",
    "\n",
    "    # Compute average Euclidean distance\n",
    "    distances = np.sqrt(np.sum((pose1 - pose2) ** 2, axis=1))\n",
    "    return np.mean(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pretrained YOLO11n-pose Pose model\n",
    "model = YOLO(\"yolo11m-pose.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\Users\\uprao\\OneDrive\\Desktop\\MotionMatch\\model\\tframe1.png: 96x160 1 person, 123.3ms\n",
      "Speed: 1.0ms preprocess, 123.3ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 160)\n",
      "Calib image\n",
      "[[[     950.82      368.16]\n",
      "  [     962.82      354.31]\n",
      "  [     936.17      353.59]\n",
      "  [     974.55      365.96]\n",
      "  [     910.03      362.95]\n",
      "  [     997.05      459.97]\n",
      "  [     866.19      455.27]\n",
      "  [     1017.2      570.62]\n",
      "  [     836.81      563.96]\n",
      "  [     1022.8      675.67]\n",
      "  [     836.25      663.35]\n",
      "  [     967.71      676.95]\n",
      "  [     881.57      675.57]\n",
      "  [     957.33      851.62]\n",
      "  [     880.85       853.3]\n",
      "  [     945.87      1002.2]\n",
      "  [     882.83      1005.7]]]\n"
     ]
    }
   ],
   "source": [
    "# Run inference on an image\n",
    "results = model(\"tframe1.png\", conf=0.3, imgsz=160, max_det=1)  # results list\n",
    "for r in results:\n",
    "    pose1 = r.keypoints.xy.numpy()\n",
    "    print(\"Calib image\")\n",
    "    print(pose1)  # print the Keypoints object containing the detected keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\Users\\uprao\\OneDrive\\Desktop\\MotionMatch\\model\\pushup.png: 96x160 1 person, 116.0ms\n",
      "Speed: 1.2ms preprocess, 116.0ms inference, 2.0ms postprocess per image at shape (1, 3, 96, 160)\n",
      "Test image\n",
      "[[[     294.63      530.11]\n",
      "  [        292      494.98]\n",
      "  [          0           0]\n",
      "  [      340.1      449.56]\n",
      "  [          0           0]\n",
      "  [     443.89      506.41]\n",
      "  [     475.78      506.65]\n",
      "  [     607.23      724.73]\n",
      "  [     628.55      672.43]\n",
      "  [     620.05      939.11]\n",
      "  [     612.77      917.53]\n",
      "  [     922.53      593.46]\n",
      "  [     940.98      624.44]\n",
      "  [     1160.4      768.36]\n",
      "  [     1184.6      778.77]\n",
      "  [     1537.4      740.64]\n",
      "  [     1514.1      716.59]]]\n"
     ]
    }
   ],
   "source": [
    "results2 = model(\"pushup.png\", conf=0.3, imgsz=160, max_det=1)  # results list\n",
    "for r in results2:\n",
    "    pose2 = r.keypoints.xy.numpy()\n",
    "    print(\"Test image\")\n",
    "    print(pose2)  # print the Keypoints object containing the detected keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "# pose1 = np.array([[100, 200], [120, 220], [110, 250]])  # Keypoints for video 1\n",
    "# pose2 = np.array([[200, 400], [240, 440], [220, 500]])  # Keypoints for video 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0.14663    -0.68319]\n",
      " [    0.23829    -0.78902]\n",
      " [    0.03475     -0.7945]\n",
      " [    0.32791    -0.69998]\n",
      " [   -0.16488    -0.72303]\n",
      " [    0.49968    0.017956]\n",
      " [   -0.49968   -0.017956]\n",
      " [    0.65369     0.86295]\n",
      " [   -0.72406      0.8121]\n",
      " [    0.69632      1.6652]\n",
      " [   -0.72832      1.5712]\n",
      " [    0.27567       1.675]\n",
      " [   -0.38217      1.6644]\n",
      " [    0.19633      3.0089]\n",
      " [   -0.38772      3.0218]\n",
      " [    0.10883      4.1587]\n",
      " [   -0.37261      4.1853]]\n"
     ]
    }
   ],
   "source": [
    "# Normalize poses\n",
    "pose1_normalized = normalize_keypoints(pose1[0], anchor_idx1=5, anchor_idx2=6)\n",
    "print(pose1_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    -5.1798     0.73927]\n",
      " [    -5.2623    -0.36226]\n",
      " [    -14.417     -15.882]\n",
      " [     -3.754     -1.7861]\n",
      " [    -14.417     -15.882]\n",
      " [   -0.49999  -0.0037403]\n",
      " [    0.49999   0.0037403]\n",
      " [     4.6215      6.8415]\n",
      " [     5.2899      5.2017]\n",
      " [     5.0233      13.563]\n",
      " [     4.7952      12.886]\n",
      " [     14.507      2.7256]\n",
      " [     15.086       3.697]\n",
      " [     21.964      8.2093]\n",
      " [     22.725      8.5356]\n",
      " [     33.787      7.3401]\n",
      " [     33.056      6.5861]]\n"
     ]
    }
   ],
   "source": [
    "pose2_normalized = normalize_keypoints(pose2[0], anchor_idx1=5, anchor_idx2=6)\n",
    "print(pose2_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pose Difference: 14.245955688134938\n"
     ]
    }
   ],
   "source": [
    "# Compute similarity\n",
    "similarity = compute_pose_similarity(pose1_normalized, pose2_normalized)\n",
    "print(\"Pose Difference:\", similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cosine_similarity(pose1, pose2):\n",
    "    # Flatten the keypoints into a single vector\n",
    "    pose1_vector = pose1.flatten()\n",
    "    pose2_vector = pose2.flatten()\n",
    "\n",
    "    # Compute dot product and magnitudes\n",
    "    dot_product = np.dot(pose1_vector, pose2_vector)\n",
    "    magnitude1 = np.linalg.norm(pose1_vector)\n",
    "    magnitude2 = np.linalg.norm(pose2_vector)\n",
    "\n",
    "    # Avoid division by zero\n",
    "    if magnitude1 == 0 or magnitude2 == 0:\n",
    "        return 0  # Treat zero-magnitude vectors as orthogonal\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    return dot_product / (magnitude1 * magnitude2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.28882775953737383\n"
     ]
    }
   ],
   "source": [
    "cos_similarity = compute_cosine_similarity(pose1_normalized, pose2_normalized)\n",
    "print(\"Cosine Similarity:\", cos_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
